
### Auto Scaling Group(ASG) 전략

1. 오토 스케일링 그룹의 다양한 스케일링 전략
	1. 수동 스케일링
		- 오토 스케일링 그룹의 크기를 수동으로 업데이트 하는 전략
		- ex) 원하는 용량, 최소 용량, 최대 용량 등의 수를 수동으로 변경
	2. 동적 스케일링
		- 단순 / 단계 스케일링
			- ex) CloudWatch 경보가 트리거 되었을 때(예를 들어 5분동안 인스턴스의 CPU 사용률이 70%를 초과할 때) 인스턴스를 오토 스케일링 그룹에 추가한다.
			- ex) CloudWatch 경보가 트리거 되었을 때(예를 들어 10분동안 인스턴스의 CPU 사용률이 30% 미만일 때) 한개의 인스턴스를 오토 스케일링 그룹에서 제거한다.
			- 단순 / 단계 스케일링이란 트리거를 정의한 다음 추가 or 삭제 할 인스턴스의 개수를 정의하기 때문이다.
		- 대상 추적 스케일링
			- 스케일링 정책을 정의하는 방식
			- ex) 오토 스케일링 그룹의 모든 EC2 인스턴스의 평균 CPU 사용률을 40%로 유지하고자 한다면 오토 스케일링 그룹은 해당 정책에 맞게 인스턴스를 자동으로 조정한다.
		- 예약 스케일링
			- 사용자가 변경 사항을 미리 알고(사용자 패턴을 기반으로) 확장을 예측하는것
			- ex) 금요일 오후 5시에 할인 행사를 하는 쇼핑몰이 트래픽이 몰릴 것을 예상하여 금요일 오후 5시에 오토 스케일링 그룹의 인스턴스 최소 용량을 10까지 높인다.
		- 예측 스케일링
			- 머신러닝을 사용해서 트래픽을 미리 예측한다
			- 과거 트래픽 패턴을 확인하는 알고리즘이 있고 과거의 패턴을 기반으로 트래픽을 예측한다.
			- 예측 스케일링인 이유는 시간이 지남에 따라 발생하는 로드를 예측하기 때문이다.
			- 예측한 기간에 도달하기 전 머신러닝으로 예측한 수의 EC2인스턴스를 자동으로 프로비저닝한다.
			- 시각적인 패턴이 존재하며 스케일링 유형에 따라 달라지는 전략을 신경쓰지 않고 머신러닝을 기반으로 쉽게 스케일링 하고자 한다면 유용하다.
			- 예측 스케일링 트래픽 도표

				![Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ba732e20-2b4d-4240-9c3b-a60fa2db89d4/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230910%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230910T094755Z&X-Amz-Expires=3600&X-Amz-Signature=030cff1bea35724030b3a23e79942641e4f6ad900137b92ea7772d0ada5f7a06&X-Amz-SignedHeaders=host&x-id=GetObject)


### S3 개요

1. Amazon S3
	- Amazon S3는 AWS의 많은 구성 요소중 핵심이 되는 서비스이다.
	- 무한 확장 스토리지이다.
		- 객체를 무한하게 저장할 수 있고 지금까지도 S3의 저장용량을 소진하지 않았다.
	- 주로 웹사이트의 **백본** 으로사용되며 많은 AWS의 서비스들도 S3를 통합해서 사용한다.
		- ex) EBS 스냅샷은 S3에 저장된다.

		※ 백본 : **여러 소형 네트워크를 묶어 대규모 파이프라인을 통해 극도로 높은 대역폭으로 다른 네트워크들의 집합과 연결되는 네트워크**

2. Amazon S3의 사용 사례
	- 백업 및 저장 등에 사용할 수 있다.
	- 데이터를 사용할 수 있기 때문에 재해 복구에 사용할 수 있다.
		- 데이터를 여러 리전에 복사하거나 보관할 수 있기 때문에
	- 고급 티어링 메커니즘을 사용해 보관비용을 절감할 수 있다.
	- 하이브리드 클라우드 스토리지로 온프레미스에서 S3로 스토리지 확장이 가능하다.
	- 애플리케이션 호스팅이 가능해 정적 웹페이지를 실행할 수 있다.
	- 미디어 호스팅이 가능해 S3자체에서 영상을 실행할 수 있다.
	- **데이터 레이크(Data Lake)**와 빅 데이터 분석으로 모든 데이터를 저장하고 S3에서 바로 분석할 수 있다.

		※ 데이터 레이크(Data Lake) : **다양한 영역으로부터 생성된 데이터를 한 곳에 모아두는 것**

	- 소프트웨어 배포 및 정적 웹사이트 배포
3. Amazon S3 - 버킷(Bucket)
	- S3의 핵심은 객체(Object)라는 파일이며 버킷(Bucket)이라는 디렉토리에 저장된다는 것이다.
	- 버킷의 이름은 전역적(Globally)으로 고유해야한다.
		- 모든 리전에 걸쳐 고유해야하며 AWS 내의 모든 계정에 걸쳐 고유해야한다.
		- 사용자의 계정 뿐 아니라 AWS의 모든 사용자 계정에 관해 고유해야한다.
		- 제한은 전역적이지만 버킷 서비스는 글로벌 서비스가 아닌 리전 수준에서 정의해야한다. 즉, 버킷은 특정 리전에서 생성되는 것이다.
	- 버킷의 명명 규칙
		- 대문자를 사용할 수 없다.
		- 밑줄(_)을 사용할 수 없다.
		- 3자 ~ 63자 사이의 길이로 작성하여야한다.
		- IP가 아니여야한다.
		- 반드시 소문자 OR 숫자로 시작하여야한다.
1. Amazon S3 - 객체(Object)
	- S3에는 거의 모든 것을 저장할 수 있다.(객체에는 무엇이든 포함할 수 있다.)
	- 객체를 저장할 때는 키(key)가 필요하며, 키는 객체의 전체 경로를 나타낸다.
		- ex) s3://my-bucket/my_file.txt 라는 파일이 존재 한다면 키는 my_file.txt 이다.
		- ex 2) s3://my-bucket/my_folder1/my_folder2/my_file.txt 라는 파일이 존재 한다면 키는 my_folder1/my_folder2/my_file.txt 이다.
		- 따라서 키는 접두사(prefix) + 객체 이름(Object name)으로 구성된다.
		- ex) s3://my-bucket/my_folder1/my_folder2/my_file.txt
	- S3 UI가 디렉토리가 있는 것처럼 사용자에게 표시 하지만 실제로는 디렉토리라는 개념이 존재하지 않는다.
		- 슬래시를 포함한 아주 긴 이름일 뿐이며 키가 길어지는 것 뿐이다.
	- 최대 객체 크기는 5TB(5,000GB)이다.
	- 5GB이상의 대용량 객체를 업로드할 때에는 여러부분으로 나누어 업로드 하여야한다.(multi-part upload를 사용해야함)
	- 본문인 콘텐츠에는 메타데이터가 존재하는데 이는 키-값 쌍으로 원하는대로 가질 수 있다.
	- 태그는 보안이나 수명 주기, 다른 부서에 관한 파일에 태그를 지정할 때 유용하다.
	- 버전 ID(Version ID)는 버전을 관리하는 번호이다.
